{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avances Laboratorio #3 \n",
    "##### Data Science  -  Universidad del Valle de Guatemala\n",
    "\n",
    "- Gustavo Andres Gonzalez Pineda 21438\n",
    "- Maria Marta Ramirez Gil 21342\n",
    "\n",
    "--------------------------------------------------------------------------------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONSUMO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>GasLicuado</th>\n",
       "      <th>Regular</th>\n",
       "      <th>Superior</th>\n",
       "      <th>Diesel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/2000</td>\n",
       "      <td>194410.48</td>\n",
       "      <td>202645.20</td>\n",
       "      <td>308156.82</td>\n",
       "      <td>634667.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/2000</td>\n",
       "      <td>174710.55</td>\n",
       "      <td>205530.96</td>\n",
       "      <td>307766.31</td>\n",
       "      <td>642380.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/2000</td>\n",
       "      <td>189234.07</td>\n",
       "      <td>229499.56</td>\n",
       "      <td>331910.29</td>\n",
       "      <td>699807.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/2000</td>\n",
       "      <td>174330.61</td>\n",
       "      <td>210680.40</td>\n",
       "      <td>315648.08</td>\n",
       "      <td>586803.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/2000</td>\n",
       "      <td>191745.15</td>\n",
       "      <td>208164.34</td>\n",
       "      <td>319667.97</td>\n",
       "      <td>656948.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>01/2024</td>\n",
       "      <td>548124.45</td>\n",
       "      <td>830708.13</td>\n",
       "      <td>658083.66</td>\n",
       "      <td>1371766.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>02/2024</td>\n",
       "      <td>526897.85</td>\n",
       "      <td>818740.16</td>\n",
       "      <td>654059.60</td>\n",
       "      <td>1352602.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>03/2024</td>\n",
       "      <td>523990.91</td>\n",
       "      <td>870771.70</td>\n",
       "      <td>671997.05</td>\n",
       "      <td>1405703.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>04/2024</td>\n",
       "      <td>531880.19</td>\n",
       "      <td>847353.15</td>\n",
       "      <td>633520.57</td>\n",
       "      <td>1442103.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>05/2024</td>\n",
       "      <td>536754.38</td>\n",
       "      <td>894533.14</td>\n",
       "      <td>692427.94</td>\n",
       "      <td>1412565.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fecha  GasLicuado    Regular   Superior      Diesel\n",
       "0    01/2000   194410.48  202645.20  308156.82   634667.06\n",
       "1    02/2000   174710.55  205530.96  307766.31   642380.66\n",
       "2    03/2000   189234.07  229499.56  331910.29   699807.25\n",
       "3    04/2000   174330.61  210680.40  315648.08   586803.98\n",
       "4    05/2000   191745.15  208164.34  319667.97   656948.20\n",
       "..       ...         ...        ...        ...         ...\n",
       "288  01/2024   548124.45  830708.13  658083.66  1371766.15\n",
       "289  02/2024   526897.85  818740.16  654059.60  1352602.93\n",
       "290  03/2024   523990.91  870771.70  671997.05  1405703.42\n",
       "291  04/2024   531880.19  847353.15  633520.57  1442103.60\n",
       "292  05/2024   536754.38  894533.14  692427.94  1412565.62\n",
       "\n",
       "[293 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------\n",
      "IMPORTACION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>GasLicuado</th>\n",
       "      <th>Regular</th>\n",
       "      <th>Superior</th>\n",
       "      <th>Diesel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/2001</td>\n",
       "      <td>194065.74</td>\n",
       "      <td>177776.50</td>\n",
       "      <td>373963.96</td>\n",
       "      <td>566101.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/2001</td>\n",
       "      <td>170703.38</td>\n",
       "      <td>123115.99</td>\n",
       "      <td>243091.07</td>\n",
       "      <td>489525.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/2001</td>\n",
       "      <td>161837.37</td>\n",
       "      <td>161726.42</td>\n",
       "      <td>312084.38</td>\n",
       "      <td>575559.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/2001</td>\n",
       "      <td>163048.64</td>\n",
       "      <td>127338.74</td>\n",
       "      <td>285054.89</td>\n",
       "      <td>437745.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/2001</td>\n",
       "      <td>171518.86</td>\n",
       "      <td>168730.19</td>\n",
       "      <td>300913.67</td>\n",
       "      <td>552609.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>01/2024</td>\n",
       "      <td>701570.80</td>\n",
       "      <td>914133.32</td>\n",
       "      <td>712333.33</td>\n",
       "      <td>1415808.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>02/2024</td>\n",
       "      <td>916541.70</td>\n",
       "      <td>740662.25</td>\n",
       "      <td>650360.11</td>\n",
       "      <td>1241501.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>03/2024</td>\n",
       "      <td>675157.48</td>\n",
       "      <td>838270.93</td>\n",
       "      <td>620077.74</td>\n",
       "      <td>1482045.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>04/2024</td>\n",
       "      <td>473940.66</td>\n",
       "      <td>886132.77</td>\n",
       "      <td>687017.96</td>\n",
       "      <td>1294706.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>05/2024</td>\n",
       "      <td>684864.46</td>\n",
       "      <td>939656.18</td>\n",
       "      <td>696970.30</td>\n",
       "      <td>1470870.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fecha  GasLicuado    Regular   Superior      Diesel\n",
       "0    01/2001   194065.74  177776.50  373963.96   566101.99\n",
       "1    02/2001   170703.38  123115.99  243091.07   489525.80\n",
       "2    03/2001   161837.37  161726.42  312084.38   575559.68\n",
       "3    04/2001   163048.64  127338.74  285054.89   437745.42\n",
       "4    05/2001   171518.86  168730.19  300913.67   552609.13\n",
       "..       ...         ...        ...        ...         ...\n",
       "276  01/2024   701570.80  914133.32  712333.33  1415808.13\n",
       "277  02/2024   916541.70  740662.25  650360.11  1241501.08\n",
       "278  03/2024   675157.48  838270.93  620077.74  1482045.48\n",
       "279  04/2024   473940.66  886132.77  687017.96  1294706.12\n",
       "280  05/2024   684864.46  939656.18  696970.30  1470870.09\n",
       "\n",
       "[281 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------\n",
      "PRECIOS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Superior</th>\n",
       "      <th>Regular</th>\n",
       "      <th>Diesel</th>\n",
       "      <th>GasLicuado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/2021</td>\n",
       "      <td>21.91</td>\n",
       "      <td>21.11</td>\n",
       "      <td>17.61</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/2021</td>\n",
       "      <td>21.91</td>\n",
       "      <td>21.11</td>\n",
       "      <td>17.61</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/2021</td>\n",
       "      <td>21.91</td>\n",
       "      <td>21.11</td>\n",
       "      <td>17.61</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/2021</td>\n",
       "      <td>21.91</td>\n",
       "      <td>21.11</td>\n",
       "      <td>17.61</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/2021</td>\n",
       "      <td>21.91</td>\n",
       "      <td>21.11</td>\n",
       "      <td>17.61</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>07/2024</td>\n",
       "      <td>32.79</td>\n",
       "      <td>31.29</td>\n",
       "      <td>28.09</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>07/2024</td>\n",
       "      <td>32.63</td>\n",
       "      <td>31.13</td>\n",
       "      <td>27.93</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>07/2024</td>\n",
       "      <td>32.63</td>\n",
       "      <td>31.13</td>\n",
       "      <td>27.93</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>07/2024</td>\n",
       "      <td>32.63</td>\n",
       "      <td>31.13</td>\n",
       "      <td>27.93</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>08/2024</td>\n",
       "      <td>32.63</td>\n",
       "      <td>31.13</td>\n",
       "      <td>27.93</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Fecha  Superior  Regular  Diesel  GasLicuado\n",
       "0     01/2021     21.91    21.11   17.61        99.0\n",
       "1     01/2021     21.91    21.11   17.61        99.0\n",
       "2     01/2021     21.91    21.11   17.61        99.0\n",
       "3     01/2021     21.91    21.11   17.61        99.0\n",
       "4     01/2021     21.91    21.11   17.61        99.0\n",
       "...       ...       ...      ...     ...         ...\n",
       "1304  07/2024     32.79    31.29   28.09       110.0\n",
       "1305  07/2024     32.63    31.13   27.93       110.0\n",
       "1306  07/2024     32.63    31.13   27.93       110.0\n",
       "1307  07/2024     32.63    31.13   27.93       110.0\n",
       "1308  08/2024     32.63    31.13   27.93       110.0\n",
       "\n",
       "[1309 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# Cargar los datos\n",
    "consumo = pd.read_csv('data/CONSUMO.csv')\n",
    "importacion = pd.read_csv('data/IMPORTACION.csv')\n",
    "precios = pd.read_csv('data/PRECIOS.csv')\n",
    "\n",
    "# Mostrar una vista previa de los datos\n",
    "print(\"CONSUMO\")\n",
    "display(consumo)\n",
    "print()\n",
    "print (\"--------------------------------------------------------\")\n",
    "print(\"IMPORTACION\")\n",
    "display(importacion)\n",
    "print()\n",
    "print (\"--------------------------------------------------------\")\n",
    "print(\"PRECIOS\")\n",
    "display(precios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 1 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para preparar los datos\n",
    "def prepare_data(series, n_lags):\n",
    "    series = series.values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_series = scaler.fit_transform(series)\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(n_lags, len(scaled_series)):\n",
    "        X.append(scaled_series[i - n_lags:i, 0])\n",
    "        y.append(scaled_series[i, 0])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    return X, y, scaler\n",
    "\n",
    "\n",
    "# Definir el número de lags\n",
    "n_lags = 10\n",
    "\n",
    "\n",
    "# Definir el modelo LSTM\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = None  # Inicializar como None\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        if self.hidden_cell is None:\n",
    "            self.hidden_cell = (torch.zeros(1, input_seq.size(0), self.hidden_layer_size),\n",
    "                                torch.zeros(1, input_seq.size(0), self.hidden_layer_size))\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq, self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out[:, -1])\n",
    "        return predictions\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        self.hidden_cell = (torch.zeros(1, batch_size, self.hidden_layer_size),\n",
    "                            torch.zeros(1, batch_size, self.hidden_layer_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar Modelo CONSUMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, epochs):\n",
    "    for i in range(epochs):\n",
    "        for seq, labels in train_loader:\n",
    "            model.init_hidden(seq.size(0))  # Inicializar con el tamaño del batch actual\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(seq)\n",
    "            single_loss = criterion(y_pred, labels)\n",
    "            single_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if i % 25 == 0:\n",
    "            print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "\n",
    "# Preparar los datos de entrenamiento y prueba\n",
    "train_size = int(len(consumo) * 0.8)\n",
    "test_size = len(consumo) - train_size\n",
    "consumo_train, consumo_test = consumo[:train_size], consumo[train_size:]\n",
    "\n",
    "X_train, y_train, scaler = prepare_data(consumo_train['GasLicuado'], n_lags)\n",
    "X_test, y_test, _ = prepare_data(consumo_test['GasLicuado'], n_lags)\n",
    "\n",
    "# Convertir a tensores\n",
    "X_train_tensors = Variable(torch.Tensor(X_train))\n",
    "y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "X_test_tensors = Variable(torch.Tensor(X_test))\n",
    "y_test_tensors = Variable(torch.Tensor(y_test))\n",
    "\n",
    "# Crear el DataLoader\n",
    "train_data = torch.utils.data.TensorDataset(X_train_tensors, y_train_tensors)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Definir los parámetros de los modelos\n",
    "params = [\n",
    "    {'hidden_layer_size': 50, 'epochs': 100, 'batch_size': 32},\n",
    "    {'hidden_layer_size': 100, 'epochs': 150, 'batch_size': 16}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\miniconda3\\envs\\my_env\\lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 0.63122451\n",
      "epoch:  25 loss: 0.01205035\n",
      "epoch:  50 loss: 0.01061409\n",
      "epoch:  75 loss: 0.01040712\n",
      "epoch:  99 loss: 0.01040050\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (1, 49, 50), got [1, 224, 50]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39minit_hidden(X_train_tensors\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))  \u001b[38;5;66;03m# Inicializar con el tamaño del batch de entrenamiento\u001b[39;00m\n\u001b[0;32m     12\u001b[0m train_predict \u001b[38;5;241m=\u001b[39m model(X_train_tensors)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 13\u001b[0m test_predict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_tensors\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Invertir escalado\u001b[39;00m\n\u001b[0;32m     16\u001b[0m train_predict \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(train_predict)\n",
      "File \u001b[1;32mc:\\Users\\maria\\miniconda3\\envs\\my_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maria\\miniconda3\\envs\\my_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[26], line 34\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[1;34m(self, input_seq)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_cell \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_cell \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, input_seq\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layer_size),\n\u001b[0;32m     33\u001b[0m                         torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, input_seq\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layer_size))\n\u001b[1;32m---> 34\u001b[0m lstm_out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_cell \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_cell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(lstm_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32mc:\\Users\\maria\\miniconda3\\envs\\my_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maria\\miniconda3\\envs\\my_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maria\\miniconda3\\envs\\my_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:913\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    910\u001b[0m             hx \u001b[38;5;241m=\u001b[39m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    912\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m--> 913\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    914\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\maria\\miniconda3\\envs\\my_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:828\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    823\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m    824\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[0;32m    825\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[0;32m    826\u001b[0m                        ):\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m--> 828\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_expected_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExpected hidden[0] size \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m, got \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    830\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    831\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\maria\\miniconda3\\envs\\my_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:266\u001b[0m, in \u001b[0;36mRNNBase.check_hidden_size\u001b[1;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_hidden_size\u001b[39m(\u001b[38;5;28mself\u001b[39m, hx: Tensor, expected_hidden_size: Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m    264\u001b[0m                       msg: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m expected_hidden_size:\n\u001b[1;32m--> 266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(expected_hidden_size, \u001b[38;5;28mlist\u001b[39m(hx\u001b[38;5;241m.\u001b[39msize())))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected hidden[0] size (1, 49, 50), got [1, 224, 50]"
     ]
    }
   ],
   "source": [
    "# Entrenar y evaluar los modelos\n",
    "for i, param in enumerate(params):\n",
    "    model = LSTMModel(input_size=1, hidden_layer_size=param['hidden_layer_size'], output_size=1)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_model(model, train_loader, criterion, optimizer, param['epochs'])\n",
    "\n",
    "    # Predicciones\n",
    "    model.eval()\n",
    "    model.init_hidden(X_train_tensors.size(0))  # Inicializar con el tamaño del batch de entrenamiento\n",
    "    train_predict = model(X_train_tensors).detach().numpy()\n",
    "    test_predict = model(X_test_tensors).detach().numpy()\n",
    "\n",
    "    # Invertir escalado\n",
    "    train_predict = scaler.inverse_transform(train_predict)\n",
    "    test_predict = scaler.inverse_transform(test_predict)\n",
    "    y_train_inv = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "    y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "    # Calcular RMSE\n",
    "    train_score = math.sqrt(mean_squared_error(y_train_inv, train_predict))\n",
    "    test_score = math.sqrt(mean_squared_error(y_test_inv, test_predict))\n",
    "\n",
    "    print(f'Model {i + 1} - Train Score: {train_score:.2f} RMSE, Test Score: {test_score:.2f} RMSE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
